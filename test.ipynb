{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from scipy.linalg import orth\n",
    "from itertools import product\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "__all__ = [\"van32\", \"van128\", \"van256\", \"van512\", \"van768\", \"van1024\"]\n",
    "\n",
    "\n",
    "class Vanilla(nn.Module):\n",
    "    def __init__(self, base, c, num_classes=10):\n",
    "        super(Vanilla, self).__init__()\n",
    "        self.base = base\n",
    "        self.fc = nn.Linear(c, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(depth, c, activation):\n",
    "    assert isinstance(depth, int)\n",
    "\n",
    "    if activation == \"tanh\":\n",
    "        act = nn.Tanh()\n",
    "    elif activation == \"relu\":\n",
    "        act = nn.ReLU()\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for stride in [1, 2, 2]:\n",
    "        conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1, stride=stride)\n",
    "        layers += [conv2d, act]\n",
    "        in_channels = c\n",
    "    for i in range(depth):\n",
    "        if i > 1:\n",
    "            conv2d = nn.Conv2d(c, c, kernel_size=3, padding=3, dilation=3, padding_mode='circular')\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(c, c, kernel_size=3, padding=1)\n",
    "        layers += [conv2d, act]\n",
    "    layers += [nn.AvgPool2d(8)]  # For mnist is 7\n",
    "    return nn.Sequential(*layers), c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def van8(c, activation, **kwargs):\n",
    "    \"\"\"Constructs a 8 layers vanilla model.\"\"\"\n",
    "    model = Vanilla(*make_layers(8, c, activation), **kwargs)\n",
    "    return model\n",
    "\n",
    "def van32(c, activation, **kwargs):\n",
    "    \"\"\"Constructs a 32 layers vanilla model.\"\"\"\n",
    "    model = Vanilla(*make_layers(32, c, activation), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def van128(c, activation, **kwargs):\n",
    "    \"\"\"Constructs a 128 layers vanilla model.\"\"\"\n",
    "    model = Vanilla(*make_layers(128, c, activation), **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sao_utils.ramanujan_constructions import *\n",
    "\n",
    "class ECO:\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        sparsity: float = None,\n",
    "        degree: int = None,\n",
    "        method: str = \"SAO\",\n",
    "        activation: str = \"tanh\",\n",
    "        in_channels: int = 3,\n",
    "        num_classes: int = 10,\n",
    "    ):\n",
    "        self.module = module\n",
    "        self.kernel_size = module.kernel_size[0]\n",
    "        self.in_ch = module.in_channels\n",
    "        self.out_ch = module.out_channels\n",
    "        self.sparsity = sparsity\n",
    "        self.degree = degree if self.sparsity is None else self._degree_from_sparsity()\n",
    "        self.in_channels = in_channels  # Input channel of the model, not the module\n",
    "        self.num_classes = num_classes\n",
    "        self.method = method\n",
    "        self.activation = activation\n",
    "        \n",
    "    def _ortho_gen(self, rows, columns) -> torch.tensor:\n",
    "        rand_matrix = torch.randn((max(rows, columns), min(rows, columns)))\n",
    "        q, _ = torch.qr(rand_matrix)\n",
    "        orthogonal_matrix = q[:, :columns]\n",
    "        return orthogonal_matrix.T if columns > rows else orthogonal_matrix       \n",
    "        \n",
    "    def _concat(self, matrix) -> torch.tensor:\n",
    "        W = torch.concat(\n",
    "            [\n",
    "                torch.concat([matrix, torch.negative(matrix)], axis=0),\n",
    "                torch.concat([torch.negative(matrix), matrix], axis=0),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        return W\n",
    "\n",
    "    def _ortho_generator(self) -> torch.tensor:\n",
    "        if (\n",
    "            self.activation == \"relu\"\n",
    "            and self.in_ch != 3  # Input convolutional layer\n",
    "        ):\n",
    "            rows = self.rows // 2\n",
    "            columns = self.columns // 2\n",
    "            orthogonal_matrix = self._concat(self._ortho_gen(rows, columns))\n",
    "            \n",
    "        else:\n",
    "            rows = self.out_ch\n",
    "            columns = self.in_ch\n",
    "            orthogonal_matrix = self._ortho_gen(rows, columns)\n",
    "            \n",
    "        return orthogonal_matrix\n",
    "    \n",
    "    def _degree_from_sparsity(self):\n",
    "        larger_dim = max(self.in_ch, self.out_ch)\n",
    "        return int((1 - self.sparsity) * larger_dim)\n",
    "\n",
    "    def _unique_ortho_tensor(self) -> torch.tensor:\n",
    "        L = (self.kernel_size**2 + 1) // 2\n",
    "        ortho_tensor = torch.zeros(L, self.out_ch, self.in_ch)\n",
    "        \n",
    "        if self.degree is not None and self.in_ch > 3:\n",
    "            constructor = Ramanujan_Constructions(self.module, degree=self.degree, activation=self.activation)\n",
    "        \n",
    "        for i in range(L):\n",
    "            ortho_tensor[i] = (\n",
    "                self._ortho_generator()\n",
    "                if (self.degree is None or self.in_ch == 3)\n",
    "                else constructor()[0] #Get only the weights given by the constructor\n",
    "            )\n",
    "            \n",
    "        return ortho_tensor.to(\"cuda\")\n",
    "\n",
    "    def _give_equiv(self, i: int, j: int):\n",
    "        i_equiv = (self.kernel_size - i) % self.kernel_size\n",
    "        j_equiv = (self.kernel_size - j) % self.kernel_size\n",
    "        return i_equiv, j_equiv\n",
    "\n",
    "    def _ortho_conv(self):\n",
    "        k = self.kernel_size\n",
    "        List1 = []\n",
    "        List2 = []\n",
    "\n",
    "        for i, j in product(range(k), range(k)):\n",
    "            eqi, eqj = self._give_equiv(i, j)\n",
    "            List1.append([i, j])\n",
    "            List2.append([eqi, eqj])\n",
    "\n",
    "        for i in List1:\n",
    "            index1 = List1.index(i)\n",
    "            index2 = List2.index(i)\n",
    "\n",
    "            if index1 > index2:\n",
    "                List1[index1] = -1\n",
    "\n",
    "        List1 = [x for x in List1 if x != -1]\n",
    "        List2 = [x for x in List2 if x not in List1]\n",
    "\n",
    "        ortho_tensor = self._unique_ortho_tensor()\n",
    "        A = torch.zeros(k, k, self.out_ch, self.in_ch)\n",
    "\n",
    "        for i in range(len(List1)):\n",
    "            p, q = List1[i]\n",
    "            A[p, q] = ortho_tensor[i]\n",
    "\n",
    "        for i in range(len(List2)):\n",
    "            p, q = List2[i]\n",
    "            equivi, equivj = self._give_equiv(p, q)\n",
    "            A[p, q] = A[equivi, equivj]\n",
    "\n",
    "        weight_mat = torch.zeros(self.out_ch, self.in_ch, k, k)\n",
    "\n",
    "        for i, j in product(range(self.out_ch), range(self.in_ch)):\n",
    "            weight_mat[i, j] = torch.fft.ifft2(A[:, :, i, j])\n",
    "            \n",
    "        return weight_mat.to(\"cuda\")\n",
    "\n",
    "    def __call__(self) -> torch.tensor:\n",
    "        return self._ortho_conv()\n",
    "        \n",
    "        \n",
    "def ECO_Constructor(module, **kwargs):\n",
    "    return ECO(module, **kwargs)()\n",
    "\n",
    "\n",
    "def ECO_Init(model, **kwargs):\n",
    "    for _, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            module.weight = nn.Parameter(ECO_Constructor(module, **kwargs))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = van8(32, 'relu').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECO_Init(model, sparsity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2442, -0.0139, -0.0139],\n",
       "          [-0.0085, -0.0015,  0.0051],\n",
       "          [-0.0085,  0.0051, -0.0015]],\n",
       "\n",
       "         [[-0.0497, -0.0326, -0.0326],\n",
       "          [-0.0082,  0.0964, -0.0131],\n",
       "          [-0.0082, -0.0131,  0.0964]],\n",
       "\n",
       "         [[-0.1105, -0.0080, -0.0080],\n",
       "          [-0.0123, -0.0191, -0.0476],\n",
       "          [-0.0123, -0.0476, -0.0191]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1791,  0.0206,  0.0206],\n",
       "          [-0.0478,  0.1403,  0.1894],\n",
       "          [-0.0478,  0.1894,  0.1403]],\n",
       "\n",
       "         [[-0.1217, -0.0086, -0.0086],\n",
       "          [ 0.0113,  0.0687,  0.0072],\n",
       "          [ 0.0113,  0.0072,  0.0687]],\n",
       "\n",
       "         [[ 0.1247, -0.0569, -0.0569],\n",
       "          [-0.0053,  0.0606, -0.0964],\n",
       "          [-0.0053, -0.0964,  0.0606]]],\n",
       "\n",
       "\n",
       "        [[[-0.2096, -0.0197, -0.0197],\n",
       "          [-0.0109,  0.0107,  0.0062],\n",
       "          [-0.0109,  0.0062,  0.0107]],\n",
       "\n",
       "         [[ 0.1287, -0.0833, -0.0833],\n",
       "          [ 0.0068, -0.0501, -0.0322],\n",
       "          [ 0.0068, -0.0322, -0.0501]],\n",
       "\n",
       "         [[-0.0696, -0.0247, -0.0247],\n",
       "          [ 0.0672,  0.0938, -0.0141],\n",
       "          [ 0.0672, -0.0141,  0.0938]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0617, -0.0095, -0.0095],\n",
       "          [ 0.0601, -0.0264, -0.0669],\n",
       "          [ 0.0601, -0.0669, -0.0264]],\n",
       "\n",
       "         [[ 0.0191, -0.1390, -0.1390],\n",
       "          [-0.1090,  0.0101, -0.0266],\n",
       "          [-0.1090, -0.0266,  0.0101]],\n",
       "\n",
       "         [[ 0.1017,  0.0074,  0.0074],\n",
       "          [-0.0874,  0.1118, -0.0601],\n",
       "          [-0.0874, -0.0601,  0.1118]]],\n",
       "\n",
       "\n",
       "        [[[-0.2895,  0.0154,  0.0154],\n",
       "          [ 0.0071, -0.0062, -0.0007],\n",
       "          [ 0.0071, -0.0007, -0.0062]],\n",
       "\n",
       "         [[-0.0385, -0.1637, -0.1637],\n",
       "          [ 0.0405,  0.1628, -0.0664],\n",
       "          [ 0.0405, -0.0664,  0.1628]],\n",
       "\n",
       "         [[ 0.0473,  0.0424,  0.0424],\n",
       "          [ 0.0612,  0.0868, -0.0099],\n",
       "          [ 0.0612, -0.0099,  0.0868]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0078, -0.0290, -0.0290],\n",
       "          [ 0.0636, -0.0801, -0.0794],\n",
       "          [ 0.0636, -0.0794, -0.0801]],\n",
       "\n",
       "         [[-0.0702,  0.1268,  0.1268],\n",
       "          [ 0.0955, -0.0349, -0.0748],\n",
       "          [ 0.0955, -0.0748, -0.0349]],\n",
       "\n",
       "         [[ 0.0100,  0.0636,  0.0636],\n",
       "          [-0.0111,  0.0319,  0.0447],\n",
       "          [-0.0111,  0.0447,  0.0319]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base[10].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
